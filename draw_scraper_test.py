#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
draw_statistics_scraper_test.py - v1.0 æ¸¬è©¦çˆ¬èŸ²

åŠŸèƒ½: æ¸¬è©¦æ˜¯å¦èƒ½çˆ¬å–é¦™æ¸¯é¦¬æœƒæª”ä½çµ±è¨ˆæ•¸æ“š

ä½¿ç”¨: python draw_statistics_scraper_test.py
"""

import requests
from bs4 import BeautifulSoup
import json
from datetime import datetime
import logging

# ===== æ—¥èªŒé…ç½® =====
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class DrawStatisticsScraperTest:
    """é¦™æ¸¯é¦¬æœƒæª”ä½çµ±è¨ˆçˆ¬èŸ² - æ¸¬è©¦ç‰ˆ"""
    
    def __init__(self):
        self.base_url = "https://racing.hkjc.com/zh-hk/local/information/draw"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'zh-HK,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Referer': 'https://racing.hkjc.com/'
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
    
    def test_connection(self):
        """æ¸¬è©¦ 1: æª¢æŸ¥é€£æ¥"""
        logger.info("="*60)
        logger.info("æ¸¬è©¦ 1: é€£æ¥æ¸¬è©¦")
        logger.info("="*60)
        
        try:
            response = self.session.get(self.base_url, timeout=10)
            logger.info(f"âœ… URL å¯è¨ªå•")
            logger.info(f"ğŸ“Š HTTP ç‹€æ…‹ç¢¼: {response.status_code}")
            logger.info(f"ğŸ“‹ Content-Type: {response.headers.get('Content-Type')}")
            logger.info(f"ğŸ“ é é¢å¤§å°: {len(response.content)} å­—ç¯€")
            
            if response.status_code == 200:
                logger.info("âœ… é€£æ¥æˆåŠŸ!")
                return True
            else:
                logger.warning(f"âš ï¸ ç‹€æ…‹ç¢¼é 200: {response.status_code}")
                return False
        
        except requests.exceptions.ConnectionError as e:
            logger.error(f"âŒ é€£æ¥å¤±æ•—: {str(e)}")
            return False
        except requests.exceptions.Timeout:
            logger.error("âŒ é€£æ¥è¶…æ™‚")
            return False
        except Exception as e:
            logger.error(f"âŒ æœªçŸ¥éŒ¯èª¤: {str(e)}")
            return False
    
    def test_html_structure(self):
        """æ¸¬è©¦ 2: åˆ†æ HTML çµæ§‹"""
        logger.info("\n" + "="*60)
        logger.info("æ¸¬è©¦ 2: HTML çµæ§‹åˆ†æ")
        logger.info("="*60)
        
        try:
            response = self.session.get(self.base_url, timeout=10)
            soup = BeautifulSoup(response.content, 'html.parser')
            
            logger.info(f"âœ… HTML è§£ææˆåŠŸ")
            
            # æŸ¥æ‰¾è¡¨æ ¼
            tables = soup.find_all('table')
            logger.info(f"ğŸ“Š æ‰¾åˆ° {len(tables)} å€‹è¡¨æ ¼")
            
            if len(tables) == 0:
                logger.warning("âš ï¸ æ²’æœ‰æ‰¾åˆ° HTML è¡¨æ ¼")
                logger.info("ğŸ’¡ å¯èƒ½åŸå› : æ•¸æ“šç”± JavaScript å‹•æ…‹åŠ è¼‰")
                return False
            
            # åˆ†æç¬¬ä¸€å€‹è¡¨æ ¼
            if len(tables) > 0:
                first_table = tables[0]
                rows = first_table.find_all('tr')
                logger.info(f"ğŸ“ˆ ç¬¬ä¸€å€‹è¡¨æ ¼: {len(rows)} è¡Œ")
                
                if len(rows) > 0:
                    cells = rows[0].find_all(['th', 'td'])
                    logger.info(f"ğŸ“‹ ç¬¬ä¸€è¡Œ: {len(cells)} åˆ—")
            
            logger.info("âœ… HTML çµæ§‹åˆ†æå®Œæˆ")
            return True
        
        except Exception as e:
            logger.error(f"âŒ åˆ†æå¤±æ•—: {str(e)}")
            return False
    
    def test_data_extraction(self):
        """æ¸¬è©¦ 3: æ•¸æ“šæå–"""
        logger.info("\n" + "="*60)
        logger.info("æ¸¬è©¦ 3: æ•¸æ“šæå–æ¸¬è©¦")
        logger.info("="*60)
        
        try:
            response = self.session.get(self.base_url, timeout=10)
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # æŸ¥æ‰¾è¡¨æ ¼
            tables = soup.find_all('table')
            
            if len(tables) == 0:
                logger.warning("âŒ æ²’æœ‰æ‰¾åˆ°è¡¨æ ¼")
                return None
            
            # å˜—è©¦æå–æ•¸æ“š
            extracted_data = {
                'timestamp': datetime.now().isoformat(),
                'url': self.base_url,
                'tables_found': len(tables),
                'samples': []
            }
            
            # å¾å‰ 3 å€‹è¡¨æ ¼æå–æ¨£æœ¬æ•¸æ“š
            for idx, table in enumerate(tables[:3]):
                rows = table.find_all('tr')
                table_data = {
                    'table_index': idx,
                    'rows': len(rows),
                    'sample_rows': []
                }
                
                # æå–å‰ 3 è¡Œ
                for row_idx, row in enumerate(rows[:3]):
                    cells = row.find_all(['th', 'td'])
                    cell_texts = [cell.get_text(strip=True) for cell in cells]
                    table_data['sample_rows'].append({
                        'row_index': row_idx,
                        'cells': len(cells),
                        'content': cell_texts[:5]  # åªä¿ç•™å‰ 5 åˆ—
                    })
                
                extracted_data['samples'].append(table_data)
            
            logger.info(f"âœ… æˆåŠŸæå– {len(extracted_data['samples'])} å€‹è¡¨æ ¼çš„æ¨£æœ¬")
            
            # æ‰“å°æ¨£æœ¬æ•¸æ“š
            logger.info("\nğŸ“Š æå–çš„æ¨£æœ¬æ•¸æ“š:")
            logger.info(json.dumps(extracted_data, indent=2, ensure_ascii=False))
            
            return extracted_data
        
        except Exception as e:
            logger.error(f"âŒ æå–å¤±æ•—: {str(e)}")
            return None
    
    def test_javascript_detection(self):
        """æ¸¬è©¦ 4: JavaScript å‹•æ…‹åŠ è¼‰æª¢æ¸¬"""
        logger.info("\n" + "="*60)
        logger.info("æ¸¬è©¦ 4: JavaScript å‹•æ…‹åŠ è¼‰æª¢æ¸¬")
        logger.info("="*60)
        
        try:
            response = self.session.get(self.base_url, timeout=10)
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # æŸ¥æ‰¾ä¸€äº›å¸¸è¦‹çš„ JavaScript æ¡†æ¶è·¡è±¡
            react_check = soup.find(id='__react')
            vue_check = soup.find(id='app')
            angular_check = soup.find('ng-app') or soup.find('[ng-app]')
            
            indicators = {
                'React': bool(react_check),
                'Vue': bool(vue_check),
                'Angular': bool(angular_check),
                'Script tags': len(soup.find_all('script'))
            }
            
            logger.info("ğŸ” æ¡†æ¶æª¢æ¸¬:")
            for framework, found in indicators.items():
                status = "âœ… ç™¼ç¾" if found else "âŒ æœªç™¼ç¾"
                logger.info(f"  {status}: {framework}")
            
            # æŸ¥æ‰¾æ•¸æ“šå®¹å™¨
            tables = soup.find_all('table')
            
            if len(tables) > 0:
                logger.info("âœ… éœæ…‹è¡¨æ ¼å­˜åœ¨ - å¯ç›´æ¥çˆ¬å–")
                return {'javascript_required': False, 'reason': 'Static HTML tables found'}
            else:
                logger.warning("âš ï¸ æœªæ‰¾åˆ°éœæ…‹è¡¨æ ¼")
                logger.info("ğŸ’¡ å¯èƒ½éœ€è¦ JavaScript æ¸²æŸ“")
                return {'javascript_required': True, 'reason': 'No static tables found'}
        
        except Exception as e:
            logger.error(f"âŒ æª¢æ¸¬å¤±æ•—: {str(e)}")
            return None
    
    def run_all_tests(self):
        """é‹è¡Œæ‰€æœ‰æ¸¬è©¦"""
        logger.info("\n\n" + "ğŸš€ "*30)
        logger.info("é¦™æ¸¯é¦¬æœƒæª”ä½çµ±è¨ˆçˆ¬èŸ² - å®Œæ•´æ¸¬è©¦")
        logger.info("ğŸš€ "*30 + "\n")
        
        results = {}
        
        # æ¸¬è©¦ 1
        results['connection'] = self.test_connection()
        
        if not results['connection']:
            logger.error("\nâŒ é€£æ¥å¤±æ•—ï¼Œç„¡æ³•ç¹¼çºŒæ¸¬è©¦")
            return results
        
        # æ¸¬è©¦ 2
        results['html_structure'] = self.test_html_structure()
        
        # æ¸¬è©¦ 3
        results['data_extraction'] = self.test_data_extraction()
        
        # æ¸¬è©¦ 4
        results['javascript_detection'] = self.test_javascript_detection()
        
        # ç”Ÿæˆå ±å‘Š
        self.generate_report(results)
        
        return results
    
    def generate_report(self, results):
        """ç”Ÿæˆæ¸¬è©¦å ±å‘Š"""
        logger.info("\n\n" + "="*60)
        logger.info("ğŸ“‹ æ¸¬è©¦å ±å‘Šç¸½çµ")
        logger.info("="*60)
        
        logger.info("\nâœ… æ¸¬è©¦çµæœ:")
        logger.info(f"  1ï¸âƒ£  é€£æ¥æ¸¬è©¦: {'âœ… é€šé' if results['connection'] else 'âŒ å¤±æ•—'}")
        logger.info(f"  2ï¸âƒ£  HTML çµæ§‹: {'âœ… é€šé' if results['html_structure'] else 'âŒ å¤±æ•—'}")
        logger.info(f"  3ï¸âƒ£  æ•¸æ“šæå–: {'âœ… é€šé' if results['data_extraction'] else 'âŒ å¤±æ•—'}")
        
        # å»ºè­°
        logger.info("\nğŸ’¡ å»ºè­°:")
        
        if results['connection'] and results['html_structure']:
            logger.info("  âœ… å¯ä»¥ä½¿ç”¨ç°¡å–®çˆ¬èŸ² (BeautifulSoup)")
            logger.info("  âœ… é è¨ˆé–‹ç™¼æ™‚é–“: 2-3 å°æ™‚")
            logger.info("  âœ… æ¨è–¦æ–¹æ¡ˆ: æ–¹æ¡ˆ A (ç°¡å–®çˆ¬èŸ²)")
        else:
            logger.info("  âš ï¸ å¯èƒ½éœ€è¦ä½¿ç”¨é«˜ç´šçˆ¬èŸ² (Selenium)")
            logger.info("  âš ï¸ é è¨ˆé–‹ç™¼æ™‚é–“: 4-6 å°æ™‚")
            logger.info("  âš ï¸ å‚™ç”¨æ–¹æ¡ˆ: æ–¹æ¡ˆ B (Selenium)")
        
        logger.info("\nğŸ“ å¾ŒçºŒæ­¥é©Ÿ:")
        logger.info("  1. ç¢ºèªçˆ¬èŸ²å¯è¡Œæ€§")
        logger.info("  2. ç·¨å¯«å®Œæ•´çˆ¬èŸ²æ¨¡å¡Š")
        logger.info("  3. å¯¦ç¾é…è…³è©•åˆ†åŠŸèƒ½")
        logger.info("  4. é›†æˆåˆ°ä¸»æ‡‰ç”¨")
        
        logger.info("\n" + "="*60)


# ===== ä¸»å‡½æ•¸ =====
if __name__ == "__main__":
    logger.info("ğŸ´ é¦™æ¸¯é¦¬æœƒæª”ä½çµ±è¨ˆçˆ¬èŸ² - æ¸¬è©¦ç‰ˆ v1.0\n")
    
    scraper = DrawStatisticsScraperTest()
    results = scraper.run_all_tests()
    
    logger.info("\n\nâœ… æ‰€æœ‰æ¸¬è©¦å®Œæˆ!")
    logger.info("ğŸ“Š è©³ç´°çµæœå·²ä¸Šæ–¹é¡¯ç¤º")
    logger.info("\nğŸ’¬ ä¸‹ä¸€æ­¥: æ ¹æ“šæ¸¬è©¦çµæœæ±ºå®šçˆ¬èŸ²æ–¹æ¡ˆ")
